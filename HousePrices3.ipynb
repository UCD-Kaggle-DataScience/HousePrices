{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1736,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datacleaner import autoclean\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1737,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('train.csv')\n",
    "data_test = pd.read_csv('test.csv')\n",
    "#print (len(data.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1738,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean data\n",
    "Id = data_test.Id\n",
    "data = data.drop(['Id'], axis=1)\n",
    "data_test = data_test.drop(['Id'], axis=1)\n",
    "#print (data.info())\n",
    "#print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1739,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean MSSubClass, add feature for PUD\n",
    "data['PUD'] = data.MSSubClass\n",
    "data.ix[[x not in [120, 150, 160, 180] for x in data.PUD], 'PUD'] = 0\n",
    "data.ix[[x in [120, 150, 160, 180] for x in data.PUD], 'PUD'] = 1\n",
    "data = data.drop(['MSSubClass'], axis=1)\n",
    "\n",
    "data_test['PUD'] = data_test.MSSubClass\n",
    "data_test.ix[[x not in [120, 150, 160, 180] for x in data_test.PUD], 'PUD'] = 0\n",
    "data_test.ix[[x in [120, 150, 160, 180] for x in data_test.PUD], 'PUD'] = 1\n",
    "data_test = data_test.drop(['MSSubClass'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean Condition1 and 2\n",
    "data['RoadProx'] = data.Condition1\n",
    "data['RailProx'] = data.Condition1\n",
    "data['FeatProx'] = data.Condition1\n",
    "\n",
    "roadind = [x in ['Artery', 'Feedr', 'Norm'] for x in data.Condition1] or [x in ['Artery', 'Feedr', 'Norm'] for x in data.Condition2]\n",
    "data.ix[np.logical_not(roadind), 'RoadProx'] = 0\n",
    "data.ix[roadind, 'RoadProx'] = 1\n",
    "\n",
    "railind = [x in ['RRNn', 'RRAn', 'RRNe', 'RRAe'] for x in data.Condition1] or [x in ['RRNn', 'RRAn', 'RRNe', 'RRAe'] for x in data.Condition2]\n",
    "data.ix[np.logical_not(railind), 'RailProx'] = 0\n",
    "data.ix[railind, 'RailProx'] = 1\n",
    "\n",
    "featind = [x in ['PosN', 'PosA'] for x in data.Condition1] or [x in ['PosN', 'PosA'] for x in data.Condition2]\n",
    "data.ix[np.logical_not(featind), 'FeatProx'] = 0\n",
    "data.ix[featind, 'FeatProx'] = 1\n",
    "\n",
    "data = data.drop(['Condition1', 'Condition2'], axis=1)\n",
    "\n",
    "data_test['RoadProx'] = data_test.Condition1\n",
    "data_test['RailProx'] = data_test.Condition1\n",
    "data_test['FeatProx'] = data_test.Condition1\n",
    "\n",
    "roadind = [x in ['Artery', 'Feedr', 'Norm'] for x in data_test.Condition1] or [x in ['Artery', 'Feedr', 'Norm'] for x in data_test.Condition2]\n",
    "data_test.ix[np.logical_not(roadind), 'RoadProx'] = 0\n",
    "data_test.ix[roadind, 'RoadProx'] = 1\n",
    "\n",
    "railind = [x in ['RRNn', 'RRAn', 'RRNe', 'RRAe'] for x in data_test.Condition1] or [x in ['RRNn', 'RRAn', 'RRNe', 'RRAe'] for x in data_test.Condition2]\n",
    "data_test.ix[np.logical_not(railind), 'RailProx'] = 0\n",
    "data_test.ix[railind, 'RailProx'] = 1\n",
    "\n",
    "featind = [x in ['PosN', 'PosA'] for x in data_test.Condition1] or [x in ['PosN', 'PosA'] for x in data_test.Condition2]\n",
    "data_test.ix[np.logical_not(featind), 'FeatProx'] = 0\n",
    "data_test.ix[featind, 'FeatProx'] = 1\n",
    "\n",
    "data_test = data_test.drop(['Condition1', 'Condition2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1741,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean square footage and num baths\n",
    "data['SqFeet'] = data['1stFlrSF'] + data['2ndFlrSF'] + data.GrLivArea\n",
    "data['Nbaths'] = data.BsmtFullBath + 0.5*data.BsmtHalfBath + data.FullBath + 0.5*data.HalfBath\n",
    "data = data.drop(['1stFlrSF', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'], axis=1)\n",
    "\n",
    "data_test['SqFeet'] = data_test['1stFlrSF'] + data_test['2ndFlrSF'] + data_test.GrLivArea\n",
    "data_test['Nbaths'] = data_test.BsmtFullBath + 0.5*data_test.BsmtHalfBath + data_test.FullBath + 0.5*data_test.HalfBath\n",
    "data_test = data_test.drop(['1stFlrSF', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge porch sqft\n",
    "data['PorchSF'] = data.WoodDeckSF + data.OpenPorchSF + data.EnclosedPorch + data['3SsnPorch'] + data.ScreenPorch\n",
    "data = data.drop(['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch'], axis=1)\n",
    "\n",
    "data_test['PorchSF'] = data_test.WoodDeckSF + data_test.OpenPorchSF + data_test.EnclosedPorch + data_test['3SsnPorch'] + data_test.ScreenPorch\n",
    "data_test = data_test.drop(['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "5          0\n",
      "6          0\n",
      "7         32\n",
      "8          0\n",
      "9          0\n",
      "10         0\n",
      "11         0\n",
      "12         0\n",
      "13         0\n",
      "14         0\n",
      "15         0\n",
      "16         0\n",
      "17         0\n",
      "18         0\n",
      "19         0\n",
      "20         0\n",
      "21         0\n",
      "22         0\n",
      "23         0\n",
      "24       668\n",
      "25         0\n",
      "26       486\n",
      "27         0\n",
      "28         0\n",
      "29         0\n",
      "        ... \n",
      "1430       0\n",
      "1431       0\n",
      "1432       0\n",
      "1433       0\n",
      "1434       0\n",
      "1435       0\n",
      "1436       0\n",
      "1437       0\n",
      "1438       0\n",
      "1439     110\n",
      "1440       0\n",
      "1441       0\n",
      "1442       0\n",
      "1443       0\n",
      "1444       0\n",
      "1445     627\n",
      "1446       0\n",
      "1447       0\n",
      "1448       0\n",
      "1449       0\n",
      "1450       0\n",
      "1451       0\n",
      "1452       0\n",
      "1453       0\n",
      "1454       0\n",
      "1455       0\n",
      "1456     163\n",
      "1457       0\n",
      "1458    1029\n",
      "1459     290\n",
      "Name: BsmtFinSF2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (data.BsmtFinSF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1744,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge Bsmt sqft\n",
    "data['BsmtSF'] = data.BsmtFinSF1 + data.BsmtFinSF2\n",
    "data = data.drop(['BsmtFinSF1', 'BsmtFinSF2'], axis=1)\n",
    "\n",
    "data_test['BsmtSF'] = data_test.BsmtFinSF1 + data_test.BsmtFinSF2\n",
    "data_test = data_test.drop(['BsmtFinSF1', 'BsmtFinSF2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1745,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean MiscFeature\n",
    "#data['HasElev'] = data.MiscFeature\n",
    "#data['HasShed'] = data.MiscFeature\n",
    "#data['HasTen']  = data.MiscFeature\n",
    "\n",
    "#elevind = [x == 'Elev' for x in data.MiscFeature]\n",
    "#data.ix[np.logical_not(elevind), 'HasElev'] = 0\n",
    "#data.ix[elevind, 'HasElev'] = 1\n",
    "\n",
    "#shedind = [x == 'Shed' for x in data.MiscFeature]\n",
    "#data.ix[np.logical_not(shedind), 'HasShed'] = 0\n",
    "#data.ix[shedind, 'HasShed'] = 1\n",
    "\n",
    "#tenind = [x == 'TenC' for x in data.MiscFeature]\n",
    "#data.ix[np.logical_not(tenind), 'HasTen'] = 0\n",
    "#data.ix[tenind, 'HasTen'] = 1\n",
    "\n",
    "#data = data.drop(['MiscFeature'], axis=1)\n",
    "#data_test = data_test.drop(['MiscFeature'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1746,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1747,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Format data\n",
    "data = autoclean(data)\n",
    "data = data.astype('int64')\n",
    "\n",
    "data_test = autoclean(data_test)\n",
    "data_test = data_test.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1748,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print (len(data.columns.values))\n",
    "print (len(data_test.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1749,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr = data.corr()\n",
    "corr_sale = corr.SalePrice.drop(['SalePrice'])\n",
    "#print (np.abs(corr_sale).sort_values(ascending=False))\n",
    "kill = corr_sale.ix[corr_sale < 0.25].to_dict()\n",
    "#for name, val in kill.items():\n",
    "#  data = data.drop([name], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1750,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Guess and check new features\n",
    "#data['Guess1'] = data.OverallQual * data.SqFeet\n",
    "#data['Guess2'] = data.BsmtQual * data.TotalBsmtSF\n",
    "#data['Guess3'] = data.OverallCond * data.SqFeet\n",
    "#data['Guess4'] = data.BsmtCond * data.BsmtSF\n",
    "#data['Guess5'] = data.BsmtFinType1 * data.BsmtFinType2 * data.BsmtSF\n",
    "#data['Guess6'] = data.Heating * data.HeatingQC\n",
    "#data['Guess7'] = data.Functional * data.SqFeet\n",
    "#data['Guess8'] = data.Fireplaces * data.FireplaceQu\n",
    "data['Guess9'] = data.OverallQual * data.OverallCond\n",
    "data['Guess10'] = data.YearBuilt * data.BsmtSF\n",
    "data['Guess11'] = data.YearBuilt * data.SqFeet\n",
    "data['Guess12'] = data.YearBuilt * data.Nbaths\n",
    "data['Guess13'] = data.TotRmsAbvGrd * data.BedroomAbvGr\n",
    "data['Guess14'] = data.TotalBsmtSF * data.SqFeet\n",
    "data['Guess15'] = data.YearBuilt * data.YearRemodAdd\n",
    "data['Guess16'] = data.SqFeet * data.LotFrontage\n",
    "#data['Guess8'] = data.ExterQual * data.Exterior1st\n",
    "#data['Guess9'] = data.ExterCond * data.Exterior1st\n",
    "#data['Guess8'] = data.PoolQC * data.PoolArea\n",
    "#data['Guess9'] = data.GarageCond * data.GarageArea\n",
    "#data = data.drop(['OverallQual', 'SqFeet', 'BsmtQual', 'TotalBsmtSF'], axis=1)\n",
    "\n",
    "\n",
    "data_test['Guess1'] = data_test.OverallQual * data_test.SqFeet\n",
    "data_test['Guess2'] = data_test.BsmtQual * data_test.TotalBsmtSF\n",
    "data_test['Guess3'] = data_test.OverallCond * data_test.SqFeet\n",
    "data_test['Guess4'] = data_test.BsmtCond * data_test.BsmtSF\n",
    "data_test['Guess5'] = data_test.BsmtFinType1 * data_test.BsmtFinType2 * data_test.BsmtSF\n",
    "data_test['Guess6'] = data_test.Heating * data_test.HeatingQC\n",
    "data_test['Guess7'] = data_test.Functional * data_test.SqFeet\n",
    "data_test['Guess8'] = data_test.Fireplaces * data_test.FireplaceQu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = data.SalePrice\n",
    "X = data.drop(['SalePrice'], axis=1)\n",
    "#print (data.head(100))\n",
    "#rint (Y)\n",
    "#print (X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularize\n",
    "#last = 'Guess2'\n",
    "#data.ix[:,:last] = (data.ix[:,:last] - data.ix[:,:last].mean()) / data.ix[:,:last].std()\n",
    "X = (X - X.mean())\n",
    "#X = (X - X.mean()) / X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into test and train sets\n",
    "#X = data[['MSSubClass', 'LotArea', 'Neighborhood', 'HouseStyle', 'FullBath', 'BedroomAbvGr']].as_matrix()\n",
    "#Y = data.SalePrice.values\n",
    "#X = data.drop(['SalePrice'], axis=1).as_matrix()\n",
    "Y = Y.values\n",
    "X = X.as_matrix()\n",
    "kf = KFold(n_splits=2)\n",
    "#for train_index, test_index in kf.split(X):\n",
    "#  X_train, X_test = X[train_index], X[test_index]\n",
    "#  Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "X_train = X\n",
    "Y_train = Y\n",
    "X_test = (data_test - data_test.mean()).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# PCA\\npca=PCA()\\nX_train=pca.fit_transform(X_train)\\nX_test=pca.transform(X_test)\\n\\nn = len(Y_test)\\ncov = np.dot(X_test.T, X_test) / n\\neigenvalues = pca.explained_variance_\\neigenvectors = pca.components_\\n#for v in eigenvectors:\\n#    print(np.dot(v.T, np.dot(cov, v)))\\n#print (eigenvalues)\\n#print (eigenvectors)\\nind = eigenvalues >= 1\\ndum = []\\nfor i in range(0, len(X_test)):\\n  dum.append(X_test[i][:31])\\nprint (len(dum[0][:31]))\\nX_test = dum\\ndum = []\\nfor i in range(0, len(X_train)):\\n    dum.append(X_train[i][:31])\\nX_train = dum\\n#X_train = X_train[ind]\\n#for eigenvalue, eigenvector in zip(eigenvalues, eigenvectors):    \\n#    print('1 ' + str(np.dot(eigenvector.T, np.dot(cov, eigenvector))))\\n#    print('2 ' + str(eigenvalue))\\n#print (sorted(eigenvalues))\\n\""
      ]
     },
     "execution_count": 1755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# PCA\n",
    "pca=PCA()\n",
    "X_train=pca.fit_transform(X_train)\n",
    "X_test=pca.transform(X_test)\n",
    "\n",
    "n = len(Y_test)\n",
    "cov = np.dot(X_test.T, X_test) / n\n",
    "eigenvalues = pca.explained_variance_\n",
    "eigenvectors = pca.components_\n",
    "#for v in eigenvectors:\n",
    "#    print(np.dot(v.T, np.dot(cov, v)))\n",
    "#print (eigenvalues)\n",
    "#print (eigenvectors)\n",
    "ind = eigenvalues >= 1\n",
    "dum = []\n",
    "for i in range(0, len(X_test)):\n",
    "  dum.append(X_test[i][:31])\n",
    "print (len(dum[0][:31]))\n",
    "X_test = dum\n",
    "dum = []\n",
    "for i in range(0, len(X_train)):\n",
    "    dum.append(X_train[i][:31])\n",
    "X_train = dum\n",
    "#X_train = X_train[ind]\n",
    "#for eigenvalue, eigenvector in zip(eigenvalues, eigenvectors):    \n",
    "#    print('1 ' + str(np.dot(eigenvector.T, np.dot(cov, eigenvector))))\n",
    "#    print('2 ' + str(eigenvalue))\n",
    "#print (sorted(eigenvalues))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1756,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RMS log error\n",
    "def RMSlog(p, a):\n",
    "  n = len(a)\n",
    "  return (np.sqrt(sum([(np.log(p[i] + 1) - np.log(a[i] + 1))**2 for i in range(0, n)]) / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1757,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "#_DT = []\n",
    "#for i in range(0, 9):\n",
    "#  clf = tree.DecisionTreeRegressor()\n",
    "#  clf = clf.fit(X_train, Y_train)\n",
    "#  Y_pred_DT = clf.predict(X_test)\n",
    "#  _DT.append(clf.score(X_test, Y_test))\n",
    "#print (str(np.mean(_DT)) + ' +/- ' + str(np.std(_DT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1758,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random forest, turn off reg and kill improves ~0.1%\n",
    "_RF = []\n",
    "_RMS = []\n",
    "for i in range(0, 9):\n",
    "  random_forest = RandomForestRegressor(n_estimators=1000)\n",
    "  random_forest.fit(X_train, Y_train)\n",
    "  Y_pred_RF = random_forest.predict(X_test)\n",
    "#  _RF.append(random_forest.score(X_test, Y_test))\n",
    "#  _RMS.append(RMSlog(Y_pred_RF, Y_test))\n",
    "#print (str(np.mean(_RF)) + ' +/- ' + str(np.std(_RF)))\n",
    "#print (str(np.mean(_RMS)) + ' +/- ' + str(np.std(_RMS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1759,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Boosted tree\n",
    "#_BDT = []\n",
    "#for i in range(0, 9):\n",
    "#  boost = AdaBoostRegressor()\n",
    "#  boost.fit(X_train, Y_train)\n",
    "#  Y_pred_BDT = boost.predict(X_test)\n",
    "#  _BDT.append(boost.score(X_test, Y_test))\n",
    "#print (str(np.mean(_BDT)) + ' +/- ' + str(np.std(_BDT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1760,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.139251094605"
      ]
     },
     "execution_count": 1760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.139251094605 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1761,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1407688538"
      ]
     },
     "execution_count": 1761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1407688538"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1762,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.142228471831"
      ]
     },
     "execution_count": 1762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.142228471831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1763,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.146138156399"
      ]
     },
     "execution_count": 1763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.146138156399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1764,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"Id\": Id,\n",
    "        \"SalePrice\": Y_pred_RF\n",
    "    })\n",
    "submission.to_csv('HousePrices.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
